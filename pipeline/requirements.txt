# dub-lite: direct dependencies only (let pip resolve transitive deps)
# Install: pip install -r requirements.txt
# Note: torch/torchaudio are pulled in by faster-whisper, coqui-tts, speechbrain, DeepFilterNet.
#       On server, ensure Python version matches local (e.g. 3.10 or 3.11).
#       Run: python -c "import nltk; nltk.download('punkt')"  # for sentence tokenization

# === API ===
fastapi>=0.100,<1
uvicorn>=0.20
python-multipart>=0.0.6
pydantic>=2.0
celery>=5.3
redis>=5.0
python-dotenv>=1.0

# === Pipeline (used by worker) ===
# Video download & audio
yt-dlp>=2024.1
pydub>=0.25

# Transcription
faster-whisper>=1.0

# Text-to-speech
coqui-tts>=0.27

# Audio separation (background vs voice)
audio-separator>=0.40

# Speaker diarization
pyannote-audio>=4.0
pyannoteai-sdk>=0.4

# Denoising
DeepFilterNet>=0.5

# Translation (LLM APIs)
groq>=1.0
google-genai>=1.50

# Translation (local / fallback)
transformers>=4.40

# Emotion classification
speechbrain>=1.0

# NLTK (sentence tokenization)
nltk>=3.8

# Audio processing
librosa>=0.10
soundfile>=0.12
pyrubberband>=0.3
numpy>=1.24,<2
